{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cluster    ML Engine\n",
      "------------------  -----------\n",
      "tcspark             spark\n"
     ]
    }
   ],
   "source": [
    "%attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "Accuracy = 0.84\n"
     ]
    }
   ],
   "source": [
    "%%tcspark --pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler \n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator  \n",
    "\n",
    "fields = StructType([\n",
    "    StructField('SepalLength', DoubleType(), False),\n",
    "    StructField('SepalWidth', DoubleType(), False),\n",
    "    StructField('PetalLength', DoubleType(), False),\n",
    "    StructField('PetalWidth', DoubleType(), False),\n",
    "    StructField('Name', StringType(), False)\n",
    "])\n",
    "\n",
    "loc='nfs' # nfs or dtap\n",
    "\n",
    "# if there is no protocol or file identifier, it is a hdfs location\n",
    "if (loc == 'nfs'):\n",
    "    nfs_repo='file:///bd-fs-mnt/repo/'\n",
    "    data=nfs_repo+'data/iris.csv'\n",
    "    model_save_loc=nfs_repo+'models/iris.spark.model'\n",
    "else:\n",
    "    data='dtap://TenantStorage/tmp/iris.csv'\n",
    "    model_save_loc='dtap://TenantStorage/tmp/iris.spark.model'\n",
    "\n",
    "\n",
    "df = spark.read.csv(data,schema=fields,header=\"True\",sep=\",\")\n",
    "#df.show(5)\n",
    "print(\"a\")\n",
    "label_encode = StringIndexer(inputCol = 'Name', outputCol = 'label')\n",
    "assembler = VectorAssembler(inputCols=df.columns[0:4],outputCol = 'features')\n",
    "scaler = StandardScaler(inputCol='features', outputCol= 'scaledFeatures')\n",
    "lr = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'label')\n",
    "##pipeline = pyspark.ml.Pipeline(stages=[label_encode,assembler,scaler,lr])\n",
    "pipeline = Pipeline(stages=[label_encode,assembler,scaler,lr])\n",
    "(train, test) = df.randomSplit([0.8, 0.2]) \n",
    "model = pipeline.fit(train)\n",
    "predict = model.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predict)    \n",
    "print(\"b\")\n",
    "print(\"Accuracy = %g\" % (accuracy))\n",
    "model.save(model_save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
